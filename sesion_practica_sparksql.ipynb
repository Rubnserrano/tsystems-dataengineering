{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dfdc34e-e9cd-4d05-8a62-dffc127e7591",
   "metadata": {},
   "source": [
    "# Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31431663-bf84-4252-a9ba-0289609cfc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"Laboratorio 1 PySpark\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dcbe4fce-8d3e-43b2-8726-7a3009f3bee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Helper function to test the correctness of the solutions\n",
    "def test(var, val, msg=\"\"):\n",
    "    print(\"1 test passed.\") if var == val else print(\"1 test failed. \" + msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6097673f-15e1-4757-ab1d-cb88c68c8709",
   "metadata": {},
   "source": [
    "## Ejercicio 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fe9d2e6-4680-4fa4-9b21-d70af4d4abb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import Row\n",
    "from pyspark.sql import functions as sql_f\n",
    "lines_df = spark.read.text('C:\\\\Users\\\\ruben\\\\Downloads\\\\quixote.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28d9b41a-d1ca-419e-874d-437a92f3cde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count(ruta):\n",
    "    lines_df = spark.read.text(ruta)\n",
    "    ordenado = lines_df.select(sql_f.explode(sql_f.split(lines_df.value, ' '))\\\n",
    "        .alias('word'))\\\n",
    "        .filter(\"word != ''\")\\\n",
    "        .groupBy('word')\\\n",
    "        .count()\\\n",
    "        .sort('count', ascending = False)\n",
    "    return ordenado.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc885aca-9a94-4d49-a34c-66207faba43b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(word='the', count=20923),\n",
       " Row(word='and', count=16606),\n",
       " Row(word='to', count=13492),\n",
       " Row(word='of', count=12866),\n",
       " Row(word='that', count=7164),\n",
       " Row(word='a', count=7003),\n",
       " Row(word='in', count=6860),\n",
       " Row(word='I', count=5756),\n",
       " Row(word='he', count=5640),\n",
       " Row(word='for', count=4534)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count('C:\\\\Users\\\\ruben\\\\Downloads\\\\quixote.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "855815bb-9815-4c90-8341-6dc4408dda6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(word='the', count=20923), Row(word='and', count=16606), Row(word='to', count=13492), Row(word='of', count=12866), Row(word='that', count=7164), Row(word='a', count=7003), Row(word='in', count=6860), Row(word='I', count=5756), Row(word='he', count=5640), Row(word='for', count=4534)]\n",
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "top10_quixote = word_count('C:\\\\Users\\\\ruben\\\\Downloads\\\\quixote.txt')\n",
    "print(top10_quixote)\n",
    "test(top10_quixote, [('the', 20923), ('and', 16606), ('to', 13492), ('of', 12866), \n",
    "                                  ('that', 7164), ('a', 7003), ('in', 6860), ('I', 5756), ('he', 5640), \n",
    "                                  ('for', 4534)], \"Try again!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67db5ff9-dfd5-4e29-a87a-aa45b8f8b773",
   "metadata": {},
   "source": [
    "# Ejercicio 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e5dc09ff-9ec7-498f-a4fb-3c2c2a501d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(column):\n",
    "    # Remove punctuation using regexp_replace, then trim and convert to lowercase\n",
    "    return lower(trim(regexp_replace(regexp_replace(\"sentence\", r'[^a-zA-Z0-9\\s]', ' '), r'\\s+', ' ')))\n",
    "import pyspark.sql.functions as sql_f # import SQL functions\n",
    "from pyspark.sql.functions import regexp_replace, lower, trim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3235d3d8-5608-44ea-b3b3-1ec24030b79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------+\n",
      "|sentence                                                      |\n",
      "+--------------------------------------------------------------+\n",
      "|Hi! How are you?                                              |\n",
      "| Removing_all*kind^of+punctuations and extra       spaces     |\n",
      "+--------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_text_example = spark.createDataFrame([(u'Hi! How are you?',),\n",
    "                                         (u' Removing_all*kind^of+punctuations and extra       spaces     ',)], ['sentence'])\n",
    "df_text_example.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d0aa2db-1761-485d-912d-ce666cc7715d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------+\n",
      "|lower(trim(regexp_replace(regexp_replace(sentence, [^a-zA-Z0-9\\s],  , 1), \\s+,  , 1)))|\n",
      "+--------------------------------------------------------------------------------------+\n",
      "|hi how are you                                                                        |\n",
      "|removing all kind of punctuations and extra spaces                                    |\n",
      "+--------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_text_example.select(remove_punctuation(sql_f.col(\"sentence\"))).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0de25299-f0e3-4c61-8a73-d2dbc1611c98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(word='the', count=22471),\n",
       " Row(word='and', count=17722),\n",
       " Row(word='to', count=14006),\n",
       " Row(word='of', count=13491),\n",
       " Row(word='that', count=7993),\n",
       " Row(word='in', count=7335),\n",
       " Row(word='a', count=7287),\n",
       " Row(word='i', count=6653),\n",
       " Row(word='he', count=6157),\n",
       " Row(word='it', count=5680)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import explode, col, lower, regexp_replace, split, trim\n",
    "\n",
    "def remove_punctuation(column):\n",
    "    return lower(trim(regexp_replace(regexp_replace(column, r'[^a-zA-Z0-9\\s]', ' '), r'\\s+', ' ')))\n",
    "\n",
    "def word_count2(ruta):\n",
    "    lines_df = spark.read.text(ruta)\n",
    "    words_df = lines_df.select(explode(split(remove_punctuation(col(\"value\")), ' ')).alias('word'))\n",
    "    words_df = words_df.filter(\"word != ''\")\n",
    "    word_counts = words_df.groupBy('word').count()\n",
    "    ordered_word_counts = word_counts.orderBy('count', ascending=False)\n",
    "    top_10_words = ordered_word_counts.take(10)\n",
    "    return top_10_words\n",
    "    \n",
    "word_count2('C:\\\\Users\\\\ruben\\\\Downloads\\\\quixote.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b70b39e1-2c58-473d-acc5-3754f5290c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "top10_quixote = word_count2('C:\\\\Users\\\\ruben\\\\Downloads\\\\quixote.txt')\n",
    "test(top10_quixote, [('the', 22471), ('and', 17722), ('to', 14006), ('of', 13491), ('that', 7993),\n",
    "                                 ('in', 7335), ('a', 7287), ('i', 6653), ('he', 6157), ('it', 5680)],\n",
    "                  'Try again!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c54b013-6e5e-428e-a8ae-6ed3815c36f2",
   "metadata": {},
   "source": [
    "# Ejercicio 2. Removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4512473d-a5b4-4057-aad8-4c21cb31cce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = ['ourselves', 'hers', 'between', 'yourself', 'but', 'again', 'there', \n",
    "              'about', 'once', 'during', 'out', 'very', 'having', 'with', 'they', \n",
    "              'own', 'an', 'be', 'some', 'for', 'do', 'its', 'yours', 'such', 'into',\n",
    "              'of', 'most', 'itself', 'other', 'off', 'is', 's', 'am', 'or', 'who', \n",
    "              'as', 'from', 'him', 'each', 'the', 'themselves', 'until', 'below',\n",
    "              'are', 'we', 'these', 'your', 'his', 'through', 'don', 'nor', 'me',\n",
    "              'were', 'her', 'more', 'himself', 'this', 'down', 'should', 'our', \n",
    "              'their', 'while', 'above', 'both', 'up', 'to', 'ours', 'had', 'she',\n",
    "              'all', 'no', 'when', 'at', 'any', 'before', 'them', 'same', 'and',\n",
    "              'been', 'have', 'in', 'will', 'on', 'does', 'yourselves', 'then', \n",
    "              'that', 'because', 'what', 'over', 'why', 'so', 'can', 'did', 'not',\n",
    "              'now', 'under', 'he', 'you', 'herself', 'has', 'just', 'where', 'too',\n",
    "              'only', 'myself', 'which', 'those', 'i', 'after', 'few', 'whom', 't',\n",
    "              'being', 'if', 'theirs', 'my', 'against', 'a', 'by', 'doing', 'it', \n",
    "              'how', 'further', 'was', 'here', 'than']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "98e6d4e1-020f-4fa8-9e60-527450587254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(word='said', count=2627),\n",
       " Row(word='quixote', count=2327),\n",
       " Row(word='sancho', count=2205),\n",
       " Row(word='one', count=1623),\n",
       " Row(word='would', count=1251),\n",
       " Row(word='thou', count=1229),\n",
       " Row(word='say', count=904),\n",
       " Row(word='good', count=889),\n",
       " Row(word='may', count=855),\n",
       " Row(word='see', count=774)]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import explode, col, lower, regexp_replace, split, trim\n",
    "\n",
    "def remove_punctuation(column):\n",
    "    return lower(trim(regexp_replace(regexp_replace(column, r'[^a-zA-Z0-9\\s]', ' '), r'\\s+', ' ')))\n",
    "\n",
    "def word_count2(ruta):\n",
    "    lines_df = spark.read.text(ruta)\n",
    "    words_df = lines_df.select(explode(split(remove_punctuation(col(\"value\")), ' ')).alias('word'))\n",
    "    words_df = words_df.filter((col(\"word\") != \"\") & (~col(\"word\").isin(stop_words))) #chatgpt\n",
    "    word_counts = words_df.groupBy('word').count()\n",
    "    ordered_word_counts = word_counts.orderBy('count', ascending=False)\n",
    "    top_10_words = ordered_word_counts.take(10)\n",
    "    return top_10_words\n",
    "    \n",
    "word_count2('C:\\\\Users\\\\ruben\\\\Downloads\\\\quixote.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ed363af0-6bb5-47c1-802e-53ce74fcccf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "top10_quixote = word_count2('C:\\\\Users\\\\ruben\\\\Downloads\\\\quixote.txt')\n",
    "test(top10_quixote, [('said', 2627), ('quixote', 2327), ('sancho', 2205), ('one', 1623), ('would', 1251),\n",
    "                                  ('thou', 1229), ('say', 904), ('good', 889), ('may', 855), ('see', 774)],\n",
    "                  'Try again!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826bf023-6bdc-4f70-8d78-8e67904fb513",
   "metadata": {},
   "source": [
    "# Histograma de la repeticion de palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4264c171-c972-482a-a980-f5429b8f217c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_reps(file_path):\n",
    "    lines_df = spark.read.text(ruta)\n",
    "    words_df = lines_df.select(explode(split(remove_punctuation(col(\"value\")), ' ')).alias('word'))\n",
    "histogram_reps('C:\\\\Users\\\\ruben\\\\Downloads\\\\quixote.txt')[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8bd66499-9745-411a-ba8d-a0e8917de391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|       word|count|\n",
      "+-----------+-----+\n",
      "|     online|    4|\n",
      "|  imitation|   12|\n",
      "|      still|  235|\n",
      "|     doubts|   13|\n",
      "|       hope|   75|\n",
      "|   everyday|    3|\n",
      "|transmitted|    1|\n",
      "| superseded|    1|\n",
      "|     leonor|    1|\n",
      "|     poetry|   23|\n",
      "|       1572|    1|\n",
      "|      turks|   23|\n",
      "|     ransom|   21|\n",
      "| concluding|    2|\n",
      "|     freaks|    4|\n",
      "|        art|  266|\n",
      "|    insipid|    1|\n",
      "|ingratitude|   10|\n",
      "|      inner|    1|\n",
      "|      besom|    1|\n",
      "+-----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lines_df = spark.read.text(ruta)\n",
    "words_df = lines_df.select(explode(split(remove_punctuation(col(\"value\")), ' ')).alias('word'))\n",
    "words_df = words_df.filter((col(\"word\") != \"\") & (~col(\"word\").isin(stop_words))) #chatgpt\n",
    "words_counts = words_df.groupBy('word').count()\n",
    "words_counts.sql_f"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
